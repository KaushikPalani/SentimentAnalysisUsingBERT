{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaushikPalani/SentimentAnalysisUsingBERT/blob/main/Sentiment_Analysis_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "qsH_qf2EyieK"
      },
      "source": [
        "# Sentiment Analysis with Deep Learning using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "6LTVg_iAyieN"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-Wqws3yieP"
      },
      "source": [
        "- Intermediate-level knowledge of Python 3 (NumPy and Pandas preferably, but not required)\n",
        "- Exposure to PyTorch usage\n",
        "- Basic understanding of Deep Learning and Language Models (BERT specifically)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_UMbf4yieS"
      },
      "source": [
        "### Project Outline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TnzCPHfyieT"
      },
      "source": [
        "**Task 1**: Introduction (this section)\n",
        "\n",
        "**Task 2**: Exploratory Data Analysis and Preprocessing\n",
        "\n",
        "**Task 3**: Training/Validation Split\n",
        "\n",
        "**Task 4**: Loading Tokenizer and Encoding our Data\n",
        "\n",
        "**Task 5**: Setting up BERT Pretrained Model\n",
        "\n",
        "**Task 6**: Creating Data Loaders\n",
        "\n",
        "**Task 7**: Setting Up Optimizer and Scheduler\n",
        "\n",
        "**Task 8**: Defining our Performance Metrics\n",
        "\n",
        "**Task 9**: Creating our Training Loop\n",
        "\n",
        "**Task 10**: Loading and Evaluating our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "cfUawIFUyieV"
      },
      "source": [
        "## Task 1: Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "hA88y-GGyieW"
      },
      "source": [
        "### What is BERT\n",
        "\n",
        "BERT is a large-scale transformer-based Language Model that can be finetuned for a variety of tasks.\n",
        "\n",
        "For more information, the original paper can be found [here](https://arxiv.org/abs/1810.04805).\n",
        "\n",
        "[HuggingFace documentation](https://huggingface.co/transformers/model_doc/bert.html)\n",
        "\n",
        "[Bert documentation](https://characters.fandom.com/wiki/Bert_(Sesame_Street) ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR2qlh6qyiee"
      },
      "source": [
        "<img src=\"Images/BERT_diagrams.pdf\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "wHEIU_ODyiei"
      },
      "source": [
        "## Task 2: Exploratory Data Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGL7bJ2Myiek"
      },
      "source": [
        "We will use the SMILE Twitter dataset.\n",
        "\n",
        "_Wang, Bo; Tsakalidis, Adam; Liakata, Maria; Zubiaga, Arkaitz; Procter, Rob; Jensen, Eric (2016): SMILE Twitter Emotion dataset. figshare. Dataset. https://doi.org/10.6084/m9.figshare.3187909.v2_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "MUNUAB4Yyiel"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "SC_EQwjYyies"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Data/smile-annotations-final.csv', names = ['id','text','category'])\n",
        "df.set_index('id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ffQ0sgTKyieu",
        "outputId": "5498b081-d7f0-4472-cd15-4bb1cd2c0ef2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'@SelectShowcase @Tate_StIves ... Replace with your wish which the artist uses in next installation! It was entralling!'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.text.iloc[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Nqip0v3Ryiew",
        "outputId": "32be4e5d-2006-4a05-ad46-6e253bc83292"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nocode               1572\n",
              "happy                1137\n",
              "not-relevant          214\n",
              "angry                  57\n",
              "surprise               35\n",
              "sad                    32\n",
              "happy|surprise         11\n",
              "happy|sad               9\n",
              "disgust|angry           7\n",
              "disgust                 6\n",
              "sad|disgust             2\n",
              "sad|angry               2\n",
              "sad|disgust|angry       1\n",
              "Name: category, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "hIrKUu0Myiex"
      },
      "outputs": [],
      "source": [
        "df = df[~df.category.str.contains('\\|')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "NLf2pPJjyiey"
      },
      "outputs": [],
      "source": [
        "df = df[df.category != 'nocode']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "w3QCYHH7yiey",
        "outputId": "5a699b67-f215-4f0f-a90d-1c1cc41df0bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "happy           1137\n",
              "not-relevant     214\n",
              "angry             57\n",
              "surprise          35\n",
              "sad               32\n",
              "disgust            6\n",
              "Name: category, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "dJ2JpKL-yiez"
      },
      "outputs": [],
      "source": [
        "possible_labels = df['category'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "aoohwu_xyiez",
        "outputId": "c25f7b65-4e48-4473-c486-b40ee8a3d8b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'happy': 0,\n",
              " 'not-relevant': 1,\n",
              " 'angry': 2,\n",
              " 'disgust': 3,\n",
              " 'sad': 4,\n",
              " 'surprise': 5}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "label_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_B_zOuZCyie1",
        "outputId": "ab733f7d-df85-4230-8a77-2b3d281f16ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611570404268883969</th>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614499696015503361</th>\n",
              "      <td>Lucky @FitzMuseum_UK! Good luck @MirandaStearn...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613601881441570816</th>\n",
              "      <td>Yr 9 art students are off to the @britishmuseu...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613696526297210880</th>\n",
              "      <td>@RAMMuseum Please vote for us as @sainsbury #s...</td>\n",
              "      <td>not-relevant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610746718641102848</th>\n",
              "      <td>#AskTheGallery Have you got plans to privatise...</td>\n",
              "      <td>not-relevant</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612648200588038144</th>\n",
              "      <td>@BarbyWT @britishmuseum so beautiful</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text  \\\n",
              "id                                                                      \n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
              "614877582664835073  @Sofabsports thank you for following me back. ...   \n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
              "611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n",
              "614499696015503361  Lucky @FitzMuseum_UK! Good luck @MirandaStearn...   \n",
              "613601881441570816  Yr 9 art students are off to the @britishmuseu...   \n",
              "613696526297210880  @RAMMuseum Please vote for us as @sainsbury #s...   \n",
              "610746718641102848  #AskTheGallery Have you got plans to privatise...   \n",
              "612648200588038144               @BarbyWT @britishmuseum so beautiful   \n",
              "\n",
              "                        category  label  \n",
              "id                                       \n",
              "614484565059596288         happy      0  \n",
              "614746522043973632         happy      0  \n",
              "614877582664835073         happy      0  \n",
              "611932373039644672         happy      0  \n",
              "611570404268883969         happy      0  \n",
              "614499696015503361         happy      0  \n",
              "613601881441570816         happy      0  \n",
              "613696526297210880  not-relevant      1  \n",
              "610746718641102848  not-relevant      1  \n",
              "612648200588038144         happy      0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'] = df.category.replace(label_dict)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "x3w_i9jfyie1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "imWkbozSyie2"
      },
      "source": [
        "## Task 3: Training/Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ERYF7Yuzyie3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "3YTdT3qqyie4"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df.index.values,\n",
        "    df.label.values,\n",
        "    test_size=0.15,\n",
        "    random_state=17,\n",
        "    stratify=df.label.values\n",
        ")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_FUChU11yie4"
      },
      "outputs": [],
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuY5hBYdyie4"
      },
      "outputs": [],
      "source": [
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz5NOrqzyie5",
        "outputId": "e2953974-e35c-4ebb-ab22-afb925ef79f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>train</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">disgust</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>train</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sad</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
              "      <th>train</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
              "      <th>train</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              text\n",
              "category     label data_type      \n",
              "angry        2     train        48\n",
              "                   val           9\n",
              "disgust      3     train         5\n",
              "                   val           1\n",
              "happy        0     train       966\n",
              "                   val         171\n",
              "not-relevant 1     train       182\n",
              "                   val          32\n",
              "sad          4     train        27\n",
              "                   val           5\n",
              "surprise     5     train        30\n",
              "                   val           5"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['category', 'label', 'data_type']).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "ZB5iYjm9yie5"
      },
      "source": [
        "## Task 4: Loading Tokenizer and Encoding our Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "3DU3i_M3yie5"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "GFxep7tHyie6"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case=True\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnsYpdLdyie8",
        "outputId": "af227190-b028-4798-cf6d-c4c44ae3081f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>613359710343929857</th>\n",
              "      <td>Over 100 people signed up for 'What's It Worth...</td>\n",
              "      <td>not-relevant</td>\n",
              "      <td>1</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611947559444172801</th>\n",
              "      <td>Wonderful experience, hearing Tim Knox’s #obje...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612264160311803905</th>\n",
              "      <td>KETTLE'S YARD: ANTIMUSEUM - meet the Archivist...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611844583224438784</th>\n",
              "      <td>Plus excellent prizes from the @britishmuseum ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615216447787270144</th>\n",
              "      <td>Feliz cumpleaños,Rubens! Happy birthday,Rubens...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614815258092421120</th>\n",
              "      <td>Bests museums apps @britishmuseum @uffizidotco...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>612216252686299136</th>\n",
              "      <td>Well done @britishmuseum - looking forward to ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611554358812090368</th>\n",
              "      <td>@Tate_StIves It was a amazing night , a pleasu...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613813229735804928</th>\n",
              "      <td>Enjoyable afternoon @kettlesyard discussing re...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610829951890120704</th>\n",
              "      <td>Beguiled, again, by the art of Andrea del Sart...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>val</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text  \\\n",
              "id                                                                      \n",
              "613359710343929857  Over 100 people signed up for 'What's It Worth...   \n",
              "611947559444172801  Wonderful experience, hearing Tim Knox’s #obje...   \n",
              "612264160311803905  KETTLE'S YARD: ANTIMUSEUM - meet the Archivist...   \n",
              "611844583224438784  Plus excellent prizes from the @britishmuseum ...   \n",
              "615216447787270144  Feliz cumpleaños,Rubens! Happy birthday,Rubens...   \n",
              "...                                                               ...   \n",
              "614815258092421120  Bests museums apps @britishmuseum @uffizidotco...   \n",
              "612216252686299136  Well done @britishmuseum - looking forward to ...   \n",
              "611554358812090368  @Tate_StIves It was a amazing night , a pleasu...   \n",
              "613813229735804928  Enjoyable afternoon @kettlesyard discussing re...   \n",
              "610829951890120704  Beguiled, again, by the art of Andrea del Sart...   \n",
              "\n",
              "                        category  label data_type  \n",
              "id                                                 \n",
              "613359710343929857  not-relevant      1       val  \n",
              "611947559444172801         happy      0       val  \n",
              "612264160311803905         happy      0       val  \n",
              "611844583224438784         happy      0       val  \n",
              "615216447787270144         happy      0       val  \n",
              "...                          ...    ...       ...  \n",
              "614815258092421120         happy      0       val  \n",
              "612216252686299136         happy      0       val  \n",
              "611554358812090368         happy      0       val  \n",
              "613813229735804928         happy      0       val  \n",
              "610829951890120704         happy      0       val  \n",
              "\n",
              "[223 rows x 4 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.data_type == 'val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PmPquMG7yie9"
      },
      "outputs": [],
      "source": [
        "encoded_train_data = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type == 'train'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "encoded_val_data = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type == 'val'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_train_data['input_ids']\n",
        "attention_masks_train = encoded_train_data['attention_mask']\n",
        "label_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
        "\n",
        "input_ids_val = encoded_val_data['input_ids']\n",
        "attention_masks_val = encoded_val_data['attention_mask']\n",
        "label_val = torch.tensor(df[df.data_type=='val'].label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "vvDkWBwPyie9"
      },
      "outputs": [],
      "source": [
        "dataset_train = TensorDataset(input_ids_train,\n",
        "                              attention_masks_train,\n",
        "                              label_train)\n",
        "dataset_val = TensorDataset(input_ids_val,\n",
        "                            attention_masks_val,\n",
        "                            label_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "FA8A39scyie9",
        "outputId": "4ef7ca6e-927f-4c87-b480-4c08d8c26bf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "223"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lmaJ3k7Xyie-",
        "outputId": "6c5f66e9-b580-40b8-d7b9-f393d06c3041"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1258"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "5_G-1p-Vyie_"
      },
      "source": [
        "## Task 5: Setting up BERT Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMo3g5E7yie_"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "6cNRACdQyifE",
        "outputId": "de2ffba4-c4bb-4e74-b9f8-b3be2d3389c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels = len(label_dict),\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "9REwdfbRyifF"
      },
      "source": [
        "## Task 6: Creating Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4X2Iv1_yifS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "p52nacWtyifU"
      },
      "outputs": [],
      "source": [
        "batch_size = 4 #32\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_val = DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "frbzciy5yifW"
      },
      "source": [
        "## Task 7: Setting Up Optimizer and Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbIS-Z1EyifX"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Jvxv1qQvyifX"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-5, # 2e-5 > 5e-5,\n",
        "    eps=1e-8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "iZuFnv_uyifX"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(dataloader_train)*epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "BjFzay8nyifY"
      },
      "source": [
        "## Task 8: Defining our Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJssgMgxyifY"
      },
      "source": [
        "Accuracy metric approach originally used in accuracy function in [this tutorial](https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWJXcJzgyifZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWaklr8vyifZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zum0rIFwyifc"
      },
      "outputs": [],
      "source": [
        "#preds = [0.1, 0.05, 0.05, 0.08, 0, 0]\n",
        "#preds = [1,0,0,0,0,0,]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyEhnyWbyifd"
      },
      "outputs": [],
      "source": [
        "def f1_score_func(preds, labels):\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, preds_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYI4Sikjyife"
      },
      "outputs": [],
      "source": [
        "def accuracy_per_class(preds, labels):\n",
        "    labels_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds = preds_flat[labels_flat==label]\n",
        "        y_true = labels_flat[labels_flat==label]\n",
        "        print(\"Class :\", labels_dict_inverse[label])\n",
        "        print(\"Accuracy :\", len(y_preds[y_preds==label])/len(y_true))\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmOm102dyife"
      },
      "source": [
        "## Task 9: Creating our Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLmsp1Lfyiff"
      },
      "source": [
        "Approach adapted from an older version of HuggingFace's `run_glue.py` script. Accessible [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgmxR9Duyiff"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "AyigDxUjyifg",
        "outputId": "0c613eba-7288-4cbb-fda4-72248d975077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6G08AVkyifh"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in tqdm(dataloader_val):\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {'input_ids':      batch[0],\n",
        "                  'attention_mask': batch[1],\n",
        "                  'labels':         batch[2],\n",
        "                 }\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, predictions, true_vals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnG5kQPNyifi",
        "outputId": "3eda4373-b0e6-4206-91f1-4b9adf899654",
        "colab": {
          "referenced_widgets": [
            "3359ddc5559e4ad386b8d326f45f0642",
            "2b02e8f257ad49f89630278f4d511615"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3359ddc5559e4ad386b8d326f45f0642",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b02e8f257ad49f89630278f4d511615",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/315 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [40], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining loss\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch))})\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:646\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    642\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[0;32m--> 646\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[1;32m    647\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    648\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in tqdm(range(1, epochs+1)):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    loss_train_total = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train,\n",
        "                        desc='Epoch {:1d}'.format(epoch),\n",
        "                        leave=False,\n",
        "                        disable=False\n",
        "                       )\n",
        "    for batch in progress_bar:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "\n",
        "        inputs = {\n",
        "            'input_ids': batch[0],\n",
        "            'attention_mask' : batch[1],\n",
        "            'labels': batch[2]\n",
        "        }\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        loss_train_total += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training loss' : '{:.3f}'.format(loss.item()/len(batch))})\n",
        "\n",
        "    torch.save(model.state_dict(), f'Models/BERT_ft_epoch{epoch}.model')\n",
        "\n",
        "    tqdm.write('\\nEpoch {epoch}')\n",
        "\n",
        "    loss_train_avg = loss_train_total/len(dataloader)\n",
        "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "\n",
        "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
        "    val_f1 = f1_score_func(predictions, true_vals)\n",
        "    tqdm.write(f'Validation loss: {val_loss}')\n",
        "    tqdm.write(f'F1 Score weighted: {val_f1}')\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlMNFW8tyifl"
      },
      "source": [
        "## Task 10: Loading and Evaluating our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2tQIRULyifl",
        "outputId": "e398c543-4a84-41eb-fc34-6df4d4d4cf78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "PE8KI89Ayifm"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "sx69WOY4yifm",
        "outputId": "6849e0cc-13b4-47f6-a277-6ae2ec000ec9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(\n",
        "    torch.load('Models/finetuned_bert_epoch_1_gpu_trained.model',\n",
        "              map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "R_TW5hUdyifn",
        "outputId": "bc9074fd-de95-47a0-8203-59abcb2f7b8a",
        "colab": {
          "referenced_widgets": [
            "5dbfac2d884e4ed9a9661a2257f9cf1a"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5dbfac2d884e4ed9a9661a2257f9cf1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "_, predictions, tru_vals = evaluate(dataloader_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "uhAdos4zyifq",
        "outputId": "39f563f2-4249-45f9-c850-d9ecc008ab80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class : happy\n",
            "Accuracy : 0.9532163742690059\n",
            "Class : not-relevant\n",
            "Accuracy : 0.625\n",
            "Class : angry\n",
            "Accuracy : 0.7777777777777778\n",
            "Class : disgust\n",
            "Accuracy : 0.0\n",
            "Class : sad\n",
            "Accuracy : 0.8\n",
            "Class : surprise\n",
            "Accuracy : 0.4\n"
          ]
        }
      ],
      "source": [
        "accuracy_per_class(predictions, tru_vals)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}